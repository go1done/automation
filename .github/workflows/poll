name: Parallel CodePipeline Execution (Artifact-Based)

on:
  workflow_dispatch:
    inputs:
      pipeline_list:
        description: 'Comma-separated list of CodePipeline names to execute (e.g., pipe-A,pipe-B,pipe-C)'
        required: true
        default: 'pipe-A,pipe-B,pipe-C'

jobs:
  # ----------------------------------------------
  # 1. SETUP: Dynamically converts the input list into a JSON matrix
  # ----------------------------------------------
  setup:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - id: set-matrix
        name: Prepare Matrix
        run: |
          PIPELINES='["'$(echo ${{ github.event.inputs.pipeline_list }} | tr -d ' ' | tr ',' '","')'"]'
          echo "matrix=$PIPELINES" >> $GITHUB_OUTPUT

  # ----------------------------------------------
  # 2. TRIGGER: Matrix job to simultaneously start pipelines and SAVE EXECUTION IDs as ARTIFACTS
  # ----------------------------------------------
  trigger-pipelines:
    needs: setup
    runs-on: ubuntu-latest
    fail-fast: false # Ensure all triggers are attempted
    strategy:
      matrix:
        pipeline_name: ${{ fromJson(needs.setup.outputs.matrix) }}

    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
          
      - name: Start Execution and Save Metadata
        id: start
        run: |
          PIPELINE_NAME="${{ matrix.pipeline_name }}"
          AWS_REGION="${{ secrets.AWS_REGION }}"
          EXECUTION_ID="TRIGGER_FAILED"
          
          echo "Attempting to start: $PIPELINE_NAME"
          
          RESULT=$(aws codepipeline start-pipeline-execution \
            --name "$PIPELINE_NAME" \
            --query 'pipelineExecutionId' \
            --output text 2>&1)
          
          # Check for successful start
          if echo "$RESULT" | grep -q '^[0-9a-f-]\{36\}$'; then
              EXECUTION_ID="$RESULT"
              echo "Started Execution ID: $EXECUTION_ID"
          else
              echo "::warning::Failed to start pipeline $PIPELINE_NAME. Output: $RESULT"
          fi
          
          # Construct the full execution metadata string: name|id|url
          URL="https://$AWS_REGION.console.aws.amazon.com/codesuite/codepipeline/pipelines/$PIPELINE_NAME/view?region=$AWS_REGION#/view/execution/$EXECUTION_ID"
          
          # Create a unique file containing the execution metadata
          # The file name is important: pipe-A.metadata
          echo "$PIPELINE_NAME|$EXECUTION_ID|$URL" > "${PIPELINE_NAME}.metadata"

      - name: Upload Execution Metadata Artifact
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-executions-metadata
          # Upload the single metadata file created in the previous step
          path: "${{ matrix.pipeline_name }}.metadata"
          retention-days: 1

  # ----------------------------------------------
  # 3. MONITOR: Collect, Aggregate, Poll, and Summarize
  # ----------------------------------------------
  monitor-pipelines:
    needs: trigger-pipelines
    runs-on: ubuntu-latest
    
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}

    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
          
      - name: Install JQ for JSON parsing
        run: sudo apt-get install -y jq

      - name: Download Execution Metadata Artifacts
        uses: actions/download-artifact@v4
        with:
          name: pipeline-executions-metadata
          path: ./metadata-files

      - name: Poll and Summarize All Executions
        id: monitor
        run: |
          # --- Environment/Setup ---
          SUMMARY_TABLE="### CodePipeline Execution Summary 📋\n"
          SUMMARY_TABLE+="| Pipeline | Execution ID | Status | Link |\n"
          SUMMARY_TABLE+="|---|---|---|---|\n"
          OVERALL_STATUS="Succeeded"
          
          # Collect all metadata lines from the downloaded artifact files
          # Each file contains one line: NAME|ID|URL
          IFS=$'\n' PIPELINES=($(find ./metadata-files -name '*.metadata' -exec cat {} +))
          
          echo "Found ${#PIPELINES[@]} pipeline execution(s) to monitor."
          
          # --- Polling Logic ---
          POLL_PIDS=()
          
          # Start background polling for each pipeline
          for META in "${PIPELINES[@]}"; do
            (
              # Note: Use read -r for clean parsing
              IFS='|' read -r NAME ID URL <<< "$META" 
              STATUS="InProgress"
              MAX_POLLS=120 # 60 minutes total (120 * 30s poll)
              POLL_COUNT=0
              
              if [ "$ID" == "TRIGGER_FAILED" ]; then
                  STATUS="TriggerFailed"
              else
                  while [ "$STATUS" == "InProgress" ] && [ $POLL_COUNT -lt $MAX_POLLS ]; do
                      STATUS=$(aws codepipeline get-pipeline-execution \
                          --pipeline-name "$NAME" \
                          --pipeline-execution-id "$ID" \
                          --query 'pipelineExecution.status' \
                          --output text 2>/dev/null)
                      
                      if [ $? -ne 0 ] || [ -z "$STATUS" ]; then
                          STATUS="PollFailed"
                          break
                      fi

                      if [ "$STATUS" == "InProgress" ]; then
                          sleep 30
                          POLL_COUNT=$((POLL_COUNT + 1))
                      fi
                  done
                  
                  if [ $POLL_COUNT -eq $MAX_POLLS ] && [ "$STATUS" == "InProgress" ]; then
                      STATUS="Timeout"
                  fi
              fi
              
              # Format line and write to a unique temp file
              EMOJI="❓"
              FINAL_STATUS="$STATUS"
              
              if [ "$STATUS" == "Succeeded" ]; then
                  EMOJI="✅"
              elif [[ "$STATUS" == "Failed" || "$STATUS" == "TriggerFailed" || "$STATUS" == "Timeout" || "$STATUS" == "PollFailed" ]]; then
                  EMOJI="❌"
                  # Write failure status to a temporary file to signal overall job failure
                  echo "Failure" > /tmp/${NAME}_status
              elif [[ "$STATUS" == "Stopped" || "$STATUS" == "Superseded" ]]; then
                  EMOJI="⚠️"
              fi
              
              LINE_OUTPUT="| $NAME | \`$ID\` | $EMOJI **$FINAL_STATUS** | [Link]($URL) |"
              echo "$LINE_OUTPUT" > /tmp/${NAME}_line
            ) & # Run in background
            POLL_PIDS+=($!)
          done
          
          # Wait for all background polling jobs to finish
          wait "${POLL_PIDS[@]}"
          
          # --- Final Summary Aggregation ---
          
          # Concatenate all individual result lines into the summary table
          find /tmp -name '*_line' -print0 | sort -z | xargs -0 cat >> temp_summary.md
          SUMMARY_TABLE+=$(cat temp_summary.md)
          
          # Check for any failure flags
          if find /tmp -name '*_status' | grep -q 'Failure'; then
              OVERALL_STATUS="Failed"
          fi
          
          # Output the final summary to the GitHub Actions Summary page
          echo -e "$SUMMARY_TABLE" >> $GITHUB_STEP_SUMMARY
          
          # Exit based on overall status
          if [ "$OVERALL_STATUS" == "Failed" ]; then
              exit 1
          else
              exit 0
          fi
